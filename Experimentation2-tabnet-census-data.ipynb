{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experiment-Tabnet-Implementation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZy6OCF4hDel"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib as plt\n",
        "import torch.nn as nn\n",
        "from torch.nn import Linear, ReLU, BatchNorm1d"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vK0cXaIgiFM"
      },
      "source": [
        "class GBN(nn.Module):\n",
        "    def __init__(self,inp,vbs=128,momentum=0.01):\n",
        "        super().__init__()\n",
        "        self.bn = nn.BatchNorm1d(inp,momentum=momentum)\n",
        "        self.vbs = vbs\n",
        "    def forward(self,x):\n",
        "        chunk = torch.chunk(x,x.size(0)//self.vbs,0)\n",
        "        res = [self.bn(y) for y in chunk]\n",
        "        return torch.cat(res,0)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-O4qlgbgrSh"
      },
      "source": [
        "class AttentionTransformer(nn.Module):\n",
        "    def __init__(self,d_a,inp_dim,relax,vbs=128):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(d_a,inp_dim)\n",
        "        self.bn = GBN(out_dim,vbs=vbs)\n",
        "        self.smax = Sparsemax()\n",
        "        self.r = relax\n",
        "    #a:feature from previous decision step\n",
        "    def forward(self,a,priors): \n",
        "        a = self.bn(self.fc(a)) \n",
        "        mask = self.smax(a*priors) \n",
        "        priors =priors*(self.r-mask)  #updating the prior\n",
        "        return mask"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lgGFJOhgrWe"
      },
      "source": [
        "class GLU(nn.Module):\n",
        "    def __init__(self,inp_dim,out_dim,fc=None,vbs=128):\n",
        "        super().__init__()\n",
        "        if fc:\n",
        "            self.fc = fc\n",
        "        else:\n",
        "            self.fc = nn.Linear(inp_dim,out_dim*2)\n",
        "        self.bn = GBN(out_dim*2,vbs=vbs) \n",
        "        self.od = out_dim\n",
        "    def forward(self,x):\n",
        "        x = self.bn(self.fc(x))\n",
        "        return x[:,:self.od]*torch.sigmoid(x[:,self.od:])\n",
        "class FeatureTransformer(nn.Module):\n",
        "    def __init__(self,inp_dim,out_dim,shared,n_ind,vbs=128):\n",
        "        super().__init__()\n",
        "        first = True\n",
        "        self.shared = nn.ModuleList()\n",
        "        if shared:\n",
        "            self.shared.append(GLU(inp_dim,out_dim,shared[0],vbs=vbs))\n",
        "            first= False    \n",
        "            for fc in shared[1:]:\n",
        "                self.shared.append(GLU(out_dim,out_dim,fc,vbs=vbs))\n",
        "        else:\n",
        "            self.shared = None\n",
        "        self.independ = nn.ModuleList()\n",
        "        if first:\n",
        "            self.independ.append(GLU(inp,out_dim,vbs=vbs))\n",
        "        for x in range(first, n_ind):\n",
        "            self.independ.append(GLU(out_dim,out_dim,vbs=vbs))\n",
        "        self.scale = torch.sqrt(torch.tensor([.5],device=device))\n",
        "    def forward(self,x):\n",
        "        if self.shared:\n",
        "            x = self.shared[0](x)\n",
        "            for glu in self.shared[1:]:\n",
        "                x = torch.add(x, glu(x))\n",
        "                x = x*self.scale\n",
        "        for glu in self.independ:\n",
        "            x = torch.add(x, glu(x))\n",
        "            x = x*self.scale\n",
        "        return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj78Dz_KgraV"
      },
      "source": [
        "class DecisionStep(nn.Module):\n",
        "    def __init__(self,inp_dim,n_d,n_a,shared,n_ind,relax,vbs=128):\n",
        "        super().__init__()\n",
        "        self.fea_tran = FeatureTransformer(inp_dim,n_d+n_a,shared,n_ind,vbs)\n",
        "        self.atten_tran =  AttentionTransformer(n_a,inp_dim,relax,vbs)\n",
        "    def forward(self,x,a,priors):\n",
        "        mask = self.atten_tran(a,priors)\n",
        "        sparse_loss = ((-1)*mask*torch.log(mask+1e-10)).mean()\n",
        "        x = self.fea_tran(x*mask)\n",
        "        return x,sparse_loss"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOfR1JAFgrdZ"
      },
      "source": [
        "class TabNet(nn.Module):\n",
        "    def __init__(self,inp_dim,final_out_dim,n_d=64,n_a=64,\n",
        "n_shared=2,n_ind=2,n_steps=5,relax=1.2,vbs=128):\n",
        "        super().__init__()\n",
        "        if n_shared>0:\n",
        "            self.shared = nn.ModuleList()\n",
        "            self.shared.append(nn.Linear(inp_dim,2*(n_d+n_a)))\n",
        "            for x in range(n_shared-1):\n",
        "                self.shared.append(nn.Linear(n_d+n_a,2*(n_d+n_a)))\n",
        "        else:\n",
        "            self.shared=None\n",
        "        self.first_step = FeatureTransformer(inp_dim,n_d+n_a,self.shared,n_ind) \n",
        "        self.steps = nn.ModuleList()\n",
        "        for x in range(n_steps-1):\n",
        "            self.steps.append(DecisionStep(inp_dim,n_d,n_a,self.shared,n_ind,relax,vbs))\n",
        "        self.fc = nn.Linear(n_d,final_out_dim)\n",
        "        self.bn = nn.BatchNorm1d(inp_dim)\n",
        "        self.n_d = n_d\n",
        "    def forward(self,x):\n",
        "        x = self.bn(x)\n",
        "        x_a = self.first_step(x)[:,self.n_d:]\n",
        "        sparse_loss = torch.zeros(1).to(x.device)\n",
        "        out = torch.zeros(x.size(0),self.n_d).to(x.device)\n",
        "        priors = torch.ones(x.shape).to(x.device)\n",
        "        for step in self.steps:\n",
        "            x_te,l = step(x,x_a,priors)\n",
        "            out += F.relu(x_te[:,:self.n_d])\n",
        "            x_a = x_te[:,self.n_d:]\n",
        "            sparse_loss += l\n",
        "        return self.fc(out),sparse_loss"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Gl4Un6lgrjL",
        "outputId": "9d367ef9-3f50-4134-dd8d-fc1c181db685"
      },
      "source": [
        "pip install pytorch-tabnet"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-3.1.1-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.9.0+cu102)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.19.5)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (4.62.0)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (3.7.4.3)\n",
            "Installing collected packages: pytorch-tabnet\n",
            "Successfully installed pytorch-tabnet-3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FOA0KDLxXsk"
      },
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
        "\n",
        "pytorch_tabnet.tab_model."
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2XFnmcOgrmB"
      },
      "source": [
        "dfs = pd.read_csv(\"adult.data\", header=None)\n",
        "#dfs.iloc[0][\"\"]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNlL_p7B3ntK"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcfzMSIZGOgN",
        "outputId": "0847ca83-f93c-41e4-d8e9-067dc98729a9"
      },
      "source": [
        "dfs.nunique()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        73\n",
              "1         9\n",
              "2     21648\n",
              "3        16\n",
              "4        16\n",
              "5         7\n",
              "6        15\n",
              "7         6\n",
              "8         5\n",
              "9         2\n",
              "10      119\n",
              "11       92\n",
              "12       94\n",
              "13       42\n",
              "14        2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vasu_migrpW"
      },
      "source": [
        "cols = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'earn']\n",
        "dfs.columns = cols"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "zTCDlbJozItd",
        "outputId": "bde685d2-8940-4352-c24d-7d9dd5f0662a"
      },
      "source": [
        "dfs.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>earn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age          workclass  fnlwgt  ... hours-per-week  native-country    earn\n",
              "0   39          State-gov   77516  ...             40   United-States   <=50K\n",
              "1   50   Self-emp-not-inc   83311  ...             13   United-States   <=50K\n",
              "2   38            Private  215646  ...             40   United-States   <=50K\n",
              "3   53            Private  234721  ...             40   United-States   <=50K\n",
              "4   28            Private  338409  ...             40            Cuba   <=50K\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYcs4ddszp9u",
        "outputId": "2816ab44-6aad-4343-d977-58ec30f39d6d"
      },
      "source": [
        "### Preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "nunique = dfs.nunique()\n",
        "types = dfs.dtypes\n",
        "\n",
        "categorical_columns = []\n",
        "categorical_dims = {}\n",
        "\n",
        "## Label Encoding\n",
        "for col in dfs.columns:\n",
        "    if types[col] == 'object' or nunique[col] < 200:\n",
        "        print(col, dfs[col].nunique())\n",
        "        l_enc = LabelEncoder()\n",
        "        dfs[col] = dfs[col].fillna(\"Fill Na\")\n",
        "        dfs[col] = l_enc.fit_transform(dfs[col].values)\n",
        "        categorical_columns.append(col)\n",
        "        categorical_dims[col] = len(l_enc.classes_)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "age 73\n",
            "workclass 9\n",
            "education 16\n",
            "education-num 16\n",
            "marital-status 7\n",
            "occupation 15\n",
            "relationship 6\n",
            "race 5\n",
            "sex 2\n",
            "capital-gain 119\n",
            "capital-loss 92\n",
            "hours-per-week 94\n",
            "native-country 42\n",
            "earn 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVOiSimWXzug",
        "outputId": "539fb9de-6d2d-4ea8-ce19-2577d0e1215f"
      },
      "source": [
        "print(categorical_columns)\n",
        "print(categorical_dims)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['age', 'workclass', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'earn']\n",
            "{'age': 73, 'workclass': 9, 'education': 16, 'education-num': 16, 'marital-status': 7, 'occupation': 15, 'relationship': 6, 'race': 5, 'sex': 2, 'capital-gain': 119, 'capital-loss': 92, 'hours-per-week': 94, 'native-country': 42, 'earn': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "zdvKlPzTTQPC",
        "outputId": "1583fc71-6017-4448-80b5-58a4089767dd"
      },
      "source": [
        "dfs.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>earn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22</td>\n",
              "      <td>7</td>\n",
              "      <td>77516</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>33</td>\n",
              "      <td>6</td>\n",
              "      <td>83311</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "      <td>215646</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>36</td>\n",
              "      <td>4</td>\n",
              "      <td>234721</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>338409</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  workclass  fnlwgt  ...  hours-per-week  native-country  earn\n",
              "0   22          7   77516  ...              39              39     0\n",
              "1   33          6   83311  ...              12              39     0\n",
              "2   21          4  215646  ...              39              39     0\n",
              "3   36          4  234721  ...              39              39     0\n",
              "4   11          4  338409  ...              39               5     0\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zyvTO6oThxD"
      },
      "source": [
        "# Fill Nan Values with mean\n",
        "dfs_indexes = dfs.index\n",
        "dfs.fillna(dfs.loc[dfs_indexes, col].mean(), inplace=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24tJ1PqmWb5X"
      },
      "source": [
        "X = dfs[['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']]\n",
        "\n",
        "y = dfs['earn']"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zJN6ZKNFKBN"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_ratio = 0.8\n",
        "validation_ratio = 0.1\n",
        "test_ratio = 0.10\n",
        "\n",
        "# Divide to 80/10/10\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1 - train_ratio)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "\n",
        "train_indices = X_train.index\n",
        "valid_indices = X_val.index\n",
        "test_indices = X_test.index"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkotwxMvGwyJ"
      },
      "source": [
        "X_train = np.asarray(X_train)\n",
        "y_train = np.asarray(y_train)\n",
        "X_val = np.asarray(X_val)\n",
        "y_val = np.asarray(y_val)\n",
        "X_test = np.asarray(X_test)\n",
        "y_test = np.asarray(y_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMXGQ_zWY28r",
        "outputId": "b0c9efb9-7721-4cec-ef36-a501dfe8d5df"
      },
      "source": [
        "# from sklearn.metrics import mean_squared_error\n",
        "# inp_dim = X_train.shape[1]\n",
        "# final_out_dim = 1\n",
        "\n",
        "# clf = TabNet(inp_dim, 1)\n",
        "# clf.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
        "# y_pred = clf.predict(X_test)\n",
        "\n",
        "# u = mean_squared_error(y_test, y_pred, squared=False)\n",
        "# print(u)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26048, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qso8SiAFWs10",
        "outputId": "fe2727a8-a6e8-4b20-d7eb-f02e7094eb7b"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "clf = TabNetClassifier(optimizer_fn=torch.optim.Adam, optimizer_params=dict(lr=2e-2), scheduler_params={\"step_size\":50, \"gamma\":0.9},\n",
        "                       scheduler_fn=torch.optim.lr_scheduler.StepLR, mask_type='entmax')\n",
        "\n",
        "clf.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "u = mean_squared_error(y_test, y_pred, squared=False)\n",
        "print(u)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device used : cuda\n",
            "epoch 0  | loss: 0.47204 | val_0_auc: 0.59224 |  0:00:01s\n",
            "epoch 1  | loss: 0.37133 | val_0_auc: 0.59898 |  0:00:03s\n",
            "epoch 2  | loss: 0.3564  | val_0_auc: 0.62016 |  0:00:04s\n",
            "epoch 3  | loss: 0.34879 | val_0_auc: 0.65889 |  0:00:06s\n",
            "epoch 4  | loss: 0.3412  | val_0_auc: 0.82206 |  0:00:07s\n",
            "epoch 5  | loss: 0.33696 | val_0_auc: 0.86525 |  0:00:09s\n",
            "epoch 6  | loss: 0.33505 | val_0_auc: 0.88116 |  0:00:10s\n",
            "epoch 7  | loss: 0.33188 | val_0_auc: 0.8868  |  0:00:11s\n",
            "epoch 8  | loss: 0.33182 | val_0_auc: 0.88876 |  0:00:13s\n",
            "epoch 9  | loss: 0.32806 | val_0_auc: 0.89395 |  0:00:14s\n",
            "epoch 10 | loss: 0.32625 | val_0_auc: 0.89697 |  0:00:16s\n",
            "epoch 11 | loss: 0.32312 | val_0_auc: 0.89597 |  0:00:17s\n",
            "epoch 12 | loss: 0.32562 | val_0_auc: 0.89893 |  0:00:19s\n",
            "epoch 13 | loss: 0.32277 | val_0_auc: 0.89823 |  0:00:20s\n",
            "epoch 14 | loss: 0.32167 | val_0_auc: 0.89926 |  0:00:21s\n",
            "epoch 15 | loss: 0.32227 | val_0_auc: 0.89987 |  0:00:23s\n",
            "epoch 16 | loss: 0.32264 | val_0_auc: 0.90016 |  0:00:24s\n",
            "epoch 17 | loss: 0.3223  | val_0_auc: 0.89519 |  0:00:26s\n",
            "epoch 18 | loss: 0.32162 | val_0_auc: 0.89858 |  0:00:27s\n",
            "epoch 19 | loss: 0.32034 | val_0_auc: 0.89734 |  0:00:29s\n",
            "epoch 20 | loss: 0.32612 | val_0_auc: 0.89825 |  0:00:30s\n",
            "epoch 21 | loss: 0.32125 | val_0_auc: 0.89917 |  0:00:32s\n",
            "epoch 22 | loss: 0.31938 | val_0_auc: 0.90023 |  0:00:33s\n",
            "epoch 23 | loss: 0.32142 | val_0_auc: 0.90085 |  0:00:34s\n",
            "epoch 24 | loss: 0.32045 | val_0_auc: 0.90043 |  0:00:36s\n",
            "epoch 25 | loss: 0.32088 | val_0_auc: 0.90055 |  0:00:37s\n",
            "epoch 26 | loss: 0.31972 | val_0_auc: 0.90292 |  0:00:39s\n",
            "epoch 27 | loss: 0.3198  | val_0_auc: 0.90404 |  0:00:40s\n",
            "epoch 28 | loss: 0.31847 | val_0_auc: 0.9019  |  0:00:42s\n",
            "epoch 29 | loss: 0.31829 | val_0_auc: 0.90342 |  0:00:43s\n",
            "epoch 30 | loss: 0.31423 | val_0_auc: 0.90463 |  0:00:45s\n",
            "epoch 31 | loss: 0.31471 | val_0_auc: 0.9064  |  0:00:46s\n",
            "epoch 32 | loss: 0.31374 | val_0_auc: 0.90737 |  0:00:47s\n",
            "epoch 33 | loss: 0.31399 | val_0_auc: 0.90606 |  0:00:49s\n",
            "epoch 34 | loss: 0.3159  | val_0_auc: 0.90716 |  0:00:50s\n",
            "epoch 35 | loss: 0.31589 | val_0_auc: 0.90571 |  0:00:52s\n",
            "epoch 36 | loss: 0.3138  | val_0_auc: 0.90645 |  0:00:53s\n",
            "epoch 37 | loss: 0.31348 | val_0_auc: 0.90459 |  0:00:54s\n",
            "epoch 38 | loss: 0.31424 | val_0_auc: 0.90476 |  0:00:56s\n",
            "epoch 39 | loss: 0.31395 | val_0_auc: 0.90655 |  0:00:57s\n",
            "epoch 40 | loss: 0.31292 | val_0_auc: 0.903   |  0:00:59s\n",
            "epoch 41 | loss: 0.31024 | val_0_auc: 0.90585 |  0:01:00s\n",
            "epoch 42 | loss: 0.31268 | val_0_auc: 0.90254 |  0:01:01s\n",
            "\n",
            "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.90737\n",
            "Best weights from best epoch are automatically used!\n",
            "0.39220216225327426\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}